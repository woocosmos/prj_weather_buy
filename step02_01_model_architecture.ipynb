{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8e7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "\n",
    "rc('font', family='AppleGothic')\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1ca4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import keras.layers as L\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error, r2_score\n",
    "from keras import backend as K\n",
    "from keras.models import load_model,Model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.data_utils import Sequence\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f609b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#재현성을 위한 seed 설정\n",
    "seed_num = 42\n",
    "np.random.seed(seed_num)\n",
    "rn.seed(seed_num)\n",
    "tf.random.set_seed(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b5004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./raw_data/final_day.csv', index_col = 0)\n",
    "weathers = ['평균기온', '일강수량', '일사량', '미세먼지'] # 종속변수\n",
    "products = data.columns[4:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5febd92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weathers = ['평균기온', '일강수량', '미세먼지'] # 종속변수\n",
    "products = ['기능성 모공관리 화장품', '냉풍기', '벽걸이 에어컨']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047bb32f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec89d8d",
   "metadata": {},
   "source": [
    "### 1. OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb3fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "\n",
    "def OLS_(data, cat):\n",
    "    X = data[weathers]\n",
    "    y = data[cat]\n",
    "    \n",
    "    model = sm.OLS(y, X).fit()\n",
    "    mse = mean_squared_error(y_true=y, y_pred = model.predict(X))\n",
    "\n",
    "    return model, model.rsquared, mse, durbin_watson(model.resid) \n",
    "    # 모델, R제곱, mse, DW지수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be2264",
   "metadata": {},
   "source": [
    "### 2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad94aa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b204d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(data, cat):\n",
    "    cols = [cat]+ weathers\n",
    "    X = data[cols].reset_index(drop=False)\n",
    "    X.rename(columns={cat:'y'}, inplace=True)\n",
    "\n",
    "    X.index = X['date']\n",
    "    del X['date']\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6a7a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scalar(X):\n",
    "    idx = X.index\n",
    "    col = X.columns\n",
    "\n",
    "    scalar = MinMaxScaler()\n",
    "    scaled_X = pd.DataFrame(scalar.fit_transform(X))\n",
    "    scaled_X.index = idx\n",
    "    scaled_X.columns = col\n",
    "\n",
    "    return scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c133f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(dataset, time_steps, y_column): \n",
    "    \n",
    "    x, y = list(), list()\n",
    "    \n",
    "    for i in range(len(dataset)): # 2년치 일별데이터면 730번 for문 실행\n",
    "        x_end_number = i + time_steps\n",
    "        y_end_number = x_end_number + y_column\n",
    "\n",
    "        if y_end_number > len(dataset): # 데이터 끝에 다다르면 끝\n",
    "            break\n",
    "\n",
    "        tmp_x = np.array(dataset)[i:x_end_number, 1:] # 1:으로 수정(y칼럼 제외)\n",
    "        tmp_y = np.array(dataset)[x_end_number:y_end_number, 0] # 0으로 수정(y칼럼)\n",
    "        \n",
    "        x.append(tmp_x)\n",
    "        y.append(tmp_y)\n",
    "        \n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1fbfe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def RMSLE_fun(origin, pred):\n",
    "#     rmsle = np.sqrt(mean_squared_log_error(origin+1, pred+1))\n",
    "#     return rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d77b25f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(data, cat, time_steps, y_columns):\n",
    "    data = build_data(data, cat)\n",
    "\n",
    "    min = data['y'].min()\n",
    "    max = data['y'].max()\n",
    "\n",
    "    X = minmax_scalar(data)\n",
    "    Xy = X.dropna()\n",
    "\n",
    "    X, y = split_xy(Xy, time_steps, y_columns)\n",
    "\n",
    "    X_train, y_train = X[:-7],y[:-7]\n",
    "    X_test, y_test = X[-7:],y[-7:]\n",
    "\n",
    "    # X_train.shape[2] = feature 개수\n",
    "    X_test=X_test.reshape(-1, time_steps, X_train.shape[2]) \n",
    "    y_test=y_test.reshape(-1, y_columns)\n",
    "\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9743c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_(data, cat, timestep=7, y_column=1):\n",
    "    X_train,y_train,X_test,y_test,min,max = data_pipeline(data, cat, timestep, y_column)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape = (None, X_train.shape[2])))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping], validation_data = (X_test, y_test))\n",
    "\n",
    "    y_pred = model.predict(X_test, batch_size=1)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = np.mean((y_test-y_pred)**2)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mean_absolute_error(y_test, y_pred)\n",
    "#     rmsle = RMSLE_fun(np.array(y_test), np.array(y_pred))\n",
    "    \n",
    "    return model, r2, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0bef5e",
   "metadata": {},
   "source": [
    "### 3. GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8953e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU_(data, cat, timestep=7, y_column=1):\n",
    "    \n",
    "    X_train,y_train,X_test,y_test,min,max = data_pipeline(data, cat, timestep, y_column)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(128, input_shape = (None, X_train.shape[2])))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping], validation_data = (X_test, y_test))\n",
    "\n",
    "    y_pred = model.predict(X_test, batch_size=1)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = np.mean((y_test-y_pred)**2)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mean_absolute_error(y_test, y_pred)\n",
    "#     rmsle = RMSLE_fun(np.array(y_test), np.array(y_pred))\n",
    "    \n",
    "    return model, r2, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1677e9e",
   "metadata": {},
   "source": [
    "### 4. RETAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2443b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RETAIN_(data, cat, timesteps=7, y_columns=1, epochs=100):\n",
    "    X_train, y_train, X_test, y_test, min, max = data_pipeline(data, cat, timesteps, y_columns)\n",
    "\n",
    "    def reshape(data):\n",
    "        return K.reshape(x=data, shape=(-1, 1, 3)) # (-1, 1, feature의 개수)\n",
    "\n",
    "    input = keras.layers.Input(shape =(timesteps, X_train.shape[2]), name='input') # (타임스텝, feature개수)\n",
    "\n",
    "    alpha = keras.layers.Bidirectional(keras.layers.LSTM(X_train.shape[2],\n",
    "                                  return_sequences=True, implementation=2),\n",
    "                                  name='alpha')\n",
    "    beta = keras.layers.Bidirectional(keras.layers.LSTM(X_train.shape[2],\n",
    "                                  return_sequences=True, implementation=2),\n",
    "                                  name='beta')\n",
    "\n",
    "    alpha_dense = keras.layers.Dense(1)\n",
    "    beta_dense = keras.layers.Dense(X_train.shape[2])\n",
    "\n",
    "    #Compute alpha, visit attention\n",
    "    alpha_out = alpha(input)\n",
    "    alpha_out = keras.layers.TimeDistributed(alpha_dense, name='alpha_dense_0')(alpha_out)\n",
    "    alpha_out = keras.layers.Softmax(axis=1,name='softmax_1')(alpha_out)\n",
    "\n",
    "    #Compute beta, codes attention\n",
    "    beta_out = beta(input)\n",
    "    beta_out = keras.layers.TimeDistributed(beta_dense)(beta_out)\n",
    "    beta_out = keras.layers.Activation('tanh',name='beta_dense_0')(beta_out)\n",
    "    #Compute context vector based on attentions and embeddings\n",
    "\n",
    "    c_t = keras.layers.Multiply()([alpha_out, beta_out, input])\n",
    "    c_t = keras.layers.Lambda(lambda x: K.sum(x, axis=1))(c_t)\n",
    "    #Reshape to 3d vector for consistency between Many to Many and Many to One implementations\n",
    "    contexts = keras.layers.Lambda(reshape)(c_t)\n",
    "\n",
    "    #Make a prediction\n",
    "    contexts = keras.layers.Dropout(0.1)(contexts)\n",
    "    output_layer = keras.layers.Dense(1, name='dOut', activation = 'linear') \n",
    "\n",
    "    #TimeDistributed is used for consistency\n",
    "    # between Many to Many and Many to One implementations\n",
    "    output = keras.layers.TimeDistributed(output_layer, name='time_distributed_out')(contexts)\n",
    "    #Define the model with appropriate inputs\n",
    "    \n",
    "    model = Model(inputs=input, outputs=[output])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', sample_weight_mode=\"temporal\",metrics=['mse', 'mae', 'mape'])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='mse', patience=10, mode='min',restore_best_weights=True)\n",
    "\n",
    "    # 모델 저장 : 학습된 모델 개별 저장함. callbacks에 modelsaver 변수 추가시 저장가능\n",
    "    # modelsaver = ModelCheckpoint(\"./models/{}_retain.hdf5\".format(cat), monitor = 'val_loss', mode = 'min', verbose=1, save_best_only=True)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=0, callbacks=[early_stopping], validation_data = (X_test,y_test))\n",
    "\n",
    "    y_pred = model.predict(X_test, batch_size=1)  \n",
    "    y_test = y_test.reshape(-1,1) *(max-min)+min\n",
    "    y_pred =y_pred.reshape(-1,1) *(max-min)+min\n",
    "\n",
    "    y_train_pred = model.predict(X_train, batch_size=1)\n",
    "    y_train_pred = y_train_pred.reshape(-1,1)\n",
    "    y_train_test = y_train.reshape(-1,1)\n",
    "\n",
    "    r2 = r2_score(np.array(y_test),np.array(y_pred)) # R2값 추가하였음\n",
    "#     rmsle = RMSLE_fun(np.array(y_test),np.array(y_pred))\n",
    "    mse = mean_squared_error(np.array(y_test),np.array(y_pred))\n",
    "#     rmse = np.sqrt(mse)\n",
    "    \n",
    "    return model, r2, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b7621b",
   "metadata": {},
   "source": [
    "### ADF test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2019b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import  adfuller\n",
    "\n",
    "def ADF_(timeseries):\n",
    "    dftest = adfuller(timeseries, autolag='AIC', maxlag = 20)\n",
    "    dfoutput = pd.Series(dftest[0:4], index = ['Test Statistic', 'p-value',  '#Lags Used', 'Number of Observations used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value(%s)'%key] = value\n",
    "    pvalue = dftest[1]\n",
    "    if pvalue < 0.05:\n",
    "#         print('p-value = %.4f. The series is likely stationary.' % pvalue)\n",
    "        return True\n",
    "    else:\n",
    "#         print('p-vale = %.4f. The series is likely non-stationary.' % pvalue)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad32f60",
   "metadata": {},
   "source": [
    "### Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "373effe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DIFF_(timeseries):\n",
    "    timeseries = timeseries - timeseries.shift()\n",
    "    timeseries = timeseries.dropna()\n",
    "    return timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23dcc8",
   "metadata": {},
   "source": [
    "### 날씨만 미리 차분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be2072d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균기온\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>평균기온</th>\n",
       "      <th>일강수량</th>\n",
       "      <th>일사량</th>\n",
       "      <th>미세먼지</th>\n",
       "      <th>기능성 링클케어 화장품</th>\n",
       "      <th>기능성 모공관리 화장품</th>\n",
       "      <th>기능성 아이케어 화장품</th>\n",
       "      <th>기능성 영양보습 화장품</th>\n",
       "      <th>기능성 트러블케어 화장품</th>\n",
       "      <th>기능성 화이트닝 화장품</th>\n",
       "      <th>...</th>\n",
       "      <th>제습기</th>\n",
       "      <th>중대형 에어컨</th>\n",
       "      <th>천장형 에어컨</th>\n",
       "      <th>초음파식 가습기</th>\n",
       "      <th>카페트매트</th>\n",
       "      <th>컨벡터</th>\n",
       "      <th>탁상/USB 선풍기</th>\n",
       "      <th>황토매트</th>\n",
       "      <th>휴대용 선풍기</th>\n",
       "      <th>히터</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.202857</td>\n",
       "      <td>32.962963</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>364</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>0.551926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.342857</td>\n",
       "      <td>40.037037</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>324</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>399</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>-1.730873</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>9.082619</td>\n",
       "      <td>23.185185</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>415</td>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>412</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>-0.178947</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>6.590238</td>\n",
       "      <td>26.423077</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>657</td>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>494</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>1.596842</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>7.451667</td>\n",
       "      <td>29.642857</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>643</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>-3.054737</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>9.605909</td>\n",
       "      <td>22.655172</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>260</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>-0.084211</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.964091</td>\n",
       "      <td>32.862069</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>167</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>2.231579</td>\n",
       "      <td>7.406667</td>\n",
       "      <td>3.125227</td>\n",
       "      <td>34.172414</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>1532</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>2.276842</td>\n",
       "      <td>0.842353</td>\n",
       "      <td>4.571591</td>\n",
       "      <td>24.296296</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>343</td>\n",
       "      <td>12</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-8.674737</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>10.475227</td>\n",
       "      <td>19.758621</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>337</td>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>730 rows × 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                평균기온      일강수량        일사량       미세먼지  기능성 링클케어 화장품  \\\n",
       "date                                                                 \n",
       "2018-01-01       NaN  0.000000   9.202857  32.962963             3   \n",
       "2018-01-02  0.551926  0.000000   7.342857  40.037037            31   \n",
       "2018-01-03 -1.730873  1.900000   9.082619  23.185185            11   \n",
       "2018-01-04 -0.178947  1.916667   6.590238  26.423077             2   \n",
       "2018-01-05  1.596842  1.160000   7.451667  29.642857             5   \n",
       "...              ...       ...        ...        ...           ...   \n",
       "2019-12-27 -3.054737  0.535714   9.605909  22.655172             8   \n",
       "2019-12-28 -0.084211  0.500000   9.964091  32.862069             2   \n",
       "2019-12-29  2.231579  7.406667   3.125227  34.172414             9   \n",
       "2019-12-30  2.276842  0.842353   4.571591  24.296296             4   \n",
       "2019-12-31 -8.674737  0.475000  10.475227  19.758621             7   \n",
       "\n",
       "            기능성 모공관리 화장품  기능성 아이케어 화장품  기능성 영양보습 화장품  기능성 트러블케어 화장품  \\\n",
       "date                                                                  \n",
       "2018-01-01            20           364            13             44   \n",
       "2018-01-02            38           324            24             47   \n",
       "2018-01-03            40           415            11             66   \n",
       "2018-01-04            27           657            11             51   \n",
       "2018-01-05            28           643             5             52   \n",
       "...                  ...           ...           ...            ...   \n",
       "2019-12-27            44           260            13             48   \n",
       "2019-12-28            28           167             7             54   \n",
       "2019-12-29            47          1532             9             59   \n",
       "2019-12-30            47           343            12             70   \n",
       "2019-12-31            46           337            18             42   \n",
       "\n",
       "            기능성 화이트닝 화장품  ...  제습기  중대형 에어컨  천장형 에어컨  초음파식 가습기  카페트매트  컨벡터  \\\n",
       "date                      ...                                                \n",
       "2018-01-01             0  ...   24        1        0       252     11   19   \n",
       "2018-01-02             0  ...   24        0        0       399     15   18   \n",
       "2018-01-03             0  ...   16        0        1       412      9   29   \n",
       "2018-01-04             1  ...    7        0        0       494     12   30   \n",
       "2018-01-05             0  ...   15        0        0       320     15   19   \n",
       "...                  ...  ...  ...      ...      ...       ...    ...  ...   \n",
       "2019-12-27             0  ...    5        0        0       271      8   20   \n",
       "2019-12-28             0  ...    7        0        0       164      4    5   \n",
       "2019-12-29             0  ...   10        0        1       189      7   10   \n",
       "2019-12-30             0  ...   22        0        0       255     11   19   \n",
       "2019-12-31             0  ...    9        0        0       328      9   19   \n",
       "\n",
       "            탁상/USB 선풍기  황토매트  휴대용 선풍기   히터  \n",
       "date                                        \n",
       "2018-01-01           0     4        1  119  \n",
       "2018-01-02           4     6        4  287  \n",
       "2018-01-03           2     7        1  284  \n",
       "2018-01-04           1     7        3  242  \n",
       "2018-01-05           3     7        3  242  \n",
       "...                ...   ...      ...  ...  \n",
       "2019-12-27           3     3        2  233  \n",
       "2019-12-28           2     4        5   79  \n",
       "2019-12-29           0    11        2  122  \n",
       "2019-12-30           4    16        1  183  \n",
       "2019-12-31           3     8        6  203  \n",
       "\n",
       "[730 rows x 387 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diff = data.copy() # 날씨 차분된 데이터\n",
    "\n",
    "for weather in weathers:\n",
    "    timeseries = data[weather]\n",
    "    if ADF_(timeseries) == False:\n",
    "        print(weather)\n",
    "        data_diff[weather] = DIFF_(timeseries)\n",
    "        \n",
    "data_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ec7dc",
   "metadata": {},
   "source": [
    "### 5. VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90972543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b201c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAR_(data, cat):\n",
    "\n",
    "    df = data[[cat]+['일강수량', '평균기온', '미세먼지', '일사량']]\n",
    "\n",
    "    model = VAR(df)\n",
    "    results_aic = []\n",
    "\n",
    "    for p in range(1,10):\n",
    "        results = model.fit(p)\n",
    "        results_aic.append(results.aic)\n",
    "\n",
    "    order = np.argmin(results_aic)+1 # AIC가 가장 작은 모델\n",
    "    fitted = model.fit(order)\n",
    "\n",
    "    forecast_input = df.values[-order:]\n",
    "    forecast_input\n",
    "\n",
    "    nobs = 10 # 학습, 검증 데이터 split 개수\n",
    "    df_train, df_test = df[0:-nobs], df[-nobs:]\n",
    "\n",
    "    fc = fitted.forecast(y=forecast_input, steps=nobs)\n",
    "    df_forecast = pd.DataFrame(fc, index=df.index[-nobs:], columns=df.columns+'_2d')\n",
    "\n",
    "\n",
    "    def invert_transformation(df_train, df_forecast, second_diff=False):\n",
    "        \"\"\"Revert back the differencing to get the forecast to original scale.\"\"\"\n",
    "        df_fc = df_forecast.copy()\n",
    "        columns = df_train.columns\n",
    "        for col in columns:        \n",
    "            # Roll back 2nd Diff\n",
    "            if second_diff:\n",
    "                df_fc[str(col)+'_1d'] = (df_train[col].iloc[-1]-df_train[col].iloc[-2]) + df_fc[str(col)+'_2d'].cumsum()\n",
    "            # Roll back 1st Diff\n",
    "            df_fc[str(col)+'_forecast'] = df_train[col].iloc[-1] + df_fc[str(col)+'_1d'].cumsum()\n",
    "        return df_fc\n",
    "\n",
    "    df_results = invert_transformation(df_train, df_forecast, second_diff=True)        \n",
    "    df_results.loc[:, [cat+'_forecast'] + ['일강수량_forecast', '평균기온_forecast','미세먼지_forecast', '일사량_forecast']]\n",
    "\n",
    "    mse = np.mean((df_results[cat+'_forecast'].values - df_test[cat])**2)\n",
    "\n",
    "    return fitted, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6997b0",
   "metadata": {},
   "source": [
    "### Granger test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe99a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# maxlag=12\n",
    "\n",
    "# test = 'ssr_chi2test'\n",
    "# def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n",
    "#     \"\"\"Check Granger Causality of all possible combinations of the Time series.\n",
    "#     The rows are the response variable, columns are predictors. The values in the table \n",
    "#     are the P-Values. P-Values lesser than the significance level (0.05), implies \n",
    "#     the Null Hypothesis that the coefficients of the corresponding past values is \n",
    "#     zero, that is, the X does not cause Y can be rejected.\n",
    "\n",
    "#     data      : pandas dataframe containing the time series variables\n",
    "#     variables : list containing names of the time series variables.\n",
    "#     \"\"\"\n",
    "#     df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "#     for c in df.columns:\n",
    "#         for r in df.index:\n",
    "#             test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "#             p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "#             if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "#             min_p_value = np.min(p_values)\n",
    "#             df.loc[r, c] = min_p_value\n",
    "#     df.columns = [var + '_x' for var in variables]\n",
    "#     df.index = [var + '_y' for var in variables]\n",
    "#     return df\n",
    "\n",
    "# grangers_causation_matrix(df, variables = df.columns)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00cf307",
   "metadata": {},
   "source": [
    "# score comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26aa9be",
   "metadata": {},
   "source": [
    "(Cohen's)\n",
    " \n",
    "small   : 0.02 ≤ R2 \n",
    "\n",
    "middle : 0.13 ≤ R2\n",
    "\n",
    "large   : 0.26 ≤ R2\n",
    "\n",
    "\n",
    "* 일반적으로 0.65~0.7을 기준으로 하므로 엄격하게 기준을 설정할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496accc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " OLS finished \n",
      "\n",
      "================ 기능성 모공관리 화장품 =================\n",
      "LSTM 완료\n"
     ]
    }
   ],
   "source": [
    "not_target = []\n",
    "target = []\n",
    "\n",
    "OLS_scores = []\n",
    "LSTM_scores = []\n",
    "RETAIN_scores = []\n",
    "GRU_scores = []\n",
    "VAR_scores = []\n",
    "\n",
    "# OLS\n",
    "for cat in products:\n",
    "    try:\n",
    "        ols_model, ols_r2, ols_mse, DW = OLS_(data, cat)\n",
    "        if (ols_r2 < 0.65) and (1.5 <= DW <= 2.5): # OLS 결과도 좋지 않고, 시계열적이지도 않으면 날씨와 관련없다고 판단\n",
    "            print(cat, ': not using this data')\n",
    "            not_target.append(cat)\n",
    "        else:\n",
    "            target.append(cat)\n",
    "            OLS_scores.append(ols_mse)\n",
    "    except:\n",
    "        OLS_scores.append(np.nan)\n",
    "\n",
    "print('\\n OLS finished \\n')\n",
    "        \n",
    "# OLS로 한 차례 걸러진 데이터 타겟으로 딥러닝, 시계열 모델링 진행\n",
    "for cat in target:\n",
    "    print('================', cat, '=================')\n",
    "    # deep learning\n",
    "    try:\n",
    "        LSTM_model, LSTM_r2, LSTM_mse = LSTM_(data, cat)\n",
    "        LSTM_scores.append(LSTM_mse)\n",
    "        print('LSTM 완료')\n",
    "    except:\n",
    "        LSTM_scores.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        RETAIN_model, RETAIN_r2, RETAIN_mse = RETAIN_(data, cat)\n",
    "        RETAIN_scores.append(RETAIN_mse)\n",
    "        print('RETAIN 완료')\n",
    "    except:\n",
    "        RETAIN_scores.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        GRU_model, GRU_r2, GRU_mse = GRU_(data, cat) \n",
    "        GRU_scores.append(GRU_mse)\n",
    "        print('GRU 완료')\n",
    "    except:\n",
    "        GRU_scores.append(np.nan)\n",
    "\n",
    "    # timeseries\n",
    "    try:\n",
    "        # 정상성 검정\n",
    "        timeseries = data[[cat]]\n",
    "        \n",
    "        if ADF_(timeseries) == False:\n",
    "            timeseries = DIFF_(timeseries) # 1차 차분\n",
    "            print('1차 차분')\n",
    "        if ADF_(timeseries) == False:\n",
    "            timeseries = DIFF_(timeseries) # 2차 차분\n",
    "            print('2차 차분')\n",
    "        if ADF_(timeseries) == False:\n",
    "            print(\"2차 차분으로 정상성 확보되지 않음 -> 확인 필요\")\n",
    "        \n",
    "        # 차분된 날씨데이터에 대체\n",
    "        data_diff[cat] = timeseries\n",
    "        data_diff.dropna(inplace=True)\n",
    "        VAR_model, VAR_mse = VAR_(data_diff, cat)\n",
    "        VAR_scores.append(VAR_mse)\n",
    "        print('VAR 완료')\n",
    "        \n",
    "    except:\n",
    "        VAR_scores.append(np.nan)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bbcc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('개수 일치해야 함')\n",
    "print(len(OLS_scores), len(LSTM_scores), len(RETAIN_scores), len(GRU_scores), len(VAR_scores), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0741062",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = {\n",
    "    'OLS': OLS_scores,\n",
    "    'LSTM': LSTM_scores,\n",
    "    'RETAIN': RETAIN_scores,\n",
    "    'GRU': GRU_scores,\n",
    "    'VAR': VAR_scores\n",
    "}\n",
    "\n",
    "final_score = pd.DataFrame(scores, index = target)\n",
    "final_score['recommended model'] = final_score.idxmin(axis=1)\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809d5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
