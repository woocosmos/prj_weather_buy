{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0991a864",
   "metadata": {},
   "source": [
    "# 최종 LSTM 모델로 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932c555",
   "metadata": {},
   "source": [
    "# 라이브러리 및 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7a2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random as rn\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "\n",
    "rc('font', family='AppleGothic')\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3045b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c89f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6965a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#재현성을 위한 seed 설정\n",
    "seed_num = 42\n",
    "np.random.seed(seed_num)\n",
    "rn.seed(seed_num)\n",
    "tf.random.set_seed(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27bbbc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./raw_data/total_day.csv', index_col = 0)\n",
    "weathers = ['평균기온', '일강수량', '일사량', '미세먼지'] # 종속변수\n",
    "products = data.columns[4:].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ad998",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c24de75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(data, cat):\n",
    "    cols = [cat]+ weathers\n",
    "    X = data[cols].reset_index(drop=False)\n",
    "    X.rename(columns={cat:'y'}, inplace=True)\n",
    "\n",
    "    X.index = X['date']\n",
    "    del X['date']\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7190ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scalar(X):\n",
    "    idx = X.index\n",
    "    col = X.columns\n",
    "\n",
    "    scalar = MinMaxScaler()\n",
    "    scaled_X = pd.DataFrame(scalar.fit_transform(X))\n",
    "    scaled_X.index = idx\n",
    "    scaled_X.columns = col\n",
    "\n",
    "    return scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8757922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(dataset, time_steps, y_column): \n",
    "    \n",
    "    x, y = list(), list()\n",
    "    \n",
    "    for i in range(len(dataset)): # 2년치 일별데이터면 730번 for문 실행\n",
    "        x_end_number = i + time_steps\n",
    "        y_end_number = x_end_number + y_column\n",
    "\n",
    "        if y_end_number > len(dataset): # 데이터 끝에 다다르면 끝\n",
    "            break\n",
    "\n",
    "        tmp_x = np.array(dataset)[i:x_end_number, 1:] # 1:으로 수정(y칼럼 제외)\n",
    "        tmp_y = np.array(dataset)[x_end_number:y_end_number, 0] # 0으로 수정(y칼럼)\n",
    "        \n",
    "        x.append(tmp_x)\n",
    "        y.append(tmp_y)\n",
    "        \n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1a190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(data, cat, time_steps, y_columns):\n",
    "    data = build_data(data, cat)\n",
    "\n",
    "    min = data['y'].min()\n",
    "    max = data['y'].max()\n",
    "\n",
    "    X = minmax_scalar(data)\n",
    "    Xy = X.dropna()\n",
    "\n",
    "    X, y = split_xy(Xy, time_steps, y_columns)\n",
    "\n",
    "    X_train, y_train = X[:-7],y[:-7]\n",
    "    X_test, y_test = X[-7:],y[-7:]\n",
    "\n",
    "    # X_train.shape[2] = feature 개수\n",
    "    X_test=X_test.reshape(-1, time_steps, X_train.shape[2]) \n",
    "    y_test=y_test.reshape(-1, y_columns)\n",
    "\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ede28457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_(data, cat, timestep=7, y_column=1):\n",
    "    X_train, y_train, X_test, y_test, min, max = data_pipeline(data, cat, timestep, y_column)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape = (None, X_train.shape[2])))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping], validation_data = (X_test, y_test))\n",
    "\n",
    "    y_pred = model.predict(X_test, batch_size=1)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = np.mean((y_test-y_pred)**2)\n",
    "    \n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mean_absolute_error(y_test, y_pred)\n",
    "#     rmsle = RMSLE_fun(np.array(y_test), np.array(y_pred))\n",
    "    \n",
    "    return model, r2, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff786a",
   "metadata": {},
   "source": [
    "# model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "092c202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = '공기청정기'\n",
    "LSTM_model, LSTM_r2, LSTM_mse = LSTM_(data, cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4449448",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-80916a8fdab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# we use the first 100 training examples as our background dataset to integrate over\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# we use the first 100 training examples as our background dataset to integrate over\n",
    "explainer = shap.DeepExplainer(LSTM_model, X_train[:100])\n",
    "\n",
    "# explain the first 10 predictions\n",
    "# explaining each prediction requires 2 * background dataset size runs\n",
    "shap_values = explainer.shap_values(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f42f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the JS visualization code\n",
    "shap.initjs()\n",
    "\n",
    "# transform the indexes to words\n",
    "words = imdb.get_word_index()\n",
    "num2word = {}\n",
    "for w in words.keys():\n",
    "    num2word[words[w]] = w\n",
    "x_test_words = np.stack([np.array(list(map(lambda x: num2word.get(x, \"NONE\"), x_test[i]))) for i in range(10)])\n",
    "\n",
    "# plot the explanation of the first prediction\n",
    "# Note the model is \"multi-output\" because it is rank-2 but only has one column\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][0], x_test_words[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
